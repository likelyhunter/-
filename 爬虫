import requests
from bs4 import BeautifulSoup
import os
from datetime import datetime

# æŒ‡å®šå›ºå®šçš„æ¡Œé¢è·¯å¾„
desktop_path = r'D:\Users\Desktop'
save_path = os.path.join(desktop_path, 'douban_movie_top250.txt')

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://movie.douban.com/'
}


def parse_html(html):
    soup = BeautifulSoup(html, 'lxml')
    movie_list = soup.find('ol', class_='grid_view')
    if not movie_list:
        return []

    results = []
    for movie in movie_list.find_all('li'):
        try:
            title_span = movie.find('span', class_='title')
            title = title_span.text.strip() if title_span else "æœªçŸ¥æ ‡é¢˜"

            rating_span = movie.find('span', class_='rating_num')
            rating = rating_span.text.strip() if rating_span else "æš‚æ— è¯„åˆ†"

            comment_span = movie.find('span', string=lambda t: t and 'äººè¯„ä»·' in t)
            comment = comment_span.text.strip() if comment_span else "0äººè¯„ä»·"

            movie_info = f"""
            â–ˆ ç”µå½±åç§°ï¼š{title}
            â˜… è±†ç“£è¯„åˆ†ï¼š{rating}
            â˜ è¯„ä»·äººæ•°ï¼š{comment}
            {'â”' * 30}"""
            results.append(movie_info)
        except Exception as e:
            print(f"è§£æå¤±è´¥ï¼š{str(e)}")
            continue
    return results


def save_to_txt():
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    if not os.path.exists(desktop_path):
        os.makedirs(desktop_path)

    with open(save_path, 'w', encoding='utf-8') as f:
        header = f"""
        {'=' * 40}
        è±†ç“£ç”µå½±TOP250ï¼ˆå®Œæ•´ç‰ˆï¼‰
        æ•°æ®æŠ“å–æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        {'=' * 40}\n\n"""
        f.write(header)

        for i in range(10):
            url = f'https://movie.douban.com/top250?start={i * 25}'
            try:
                response = requests.get(url, headers=headers, timeout=15)
                response.raise_for_status()

                movie_data = parse_html(response.text)
                if movie_data:
                    f.write('\n'.join(movie_data))
                    f.write('\n')  # åˆ†é¡µé—´éš”
                    print(f'âœ… å·²æˆåŠŸæŠ“å–ç¬¬ {i + 1} é¡µæ•°æ®')
                else:
                    print(f'âš  ç¬¬ {i + 1} é¡µæ— æ•°æ®')
            except Exception as e:
                print(f'âŒ ç¬¬ {i + 1} é¡µæŠ“å–å¤±è´¥: {str(e)}')
                continue


if __name__ == '__main__':
    save_to_txt()
    print(f'\nğŸ‰ æ•°æ®å·²ä¿å­˜åˆ°æ¡Œé¢æ–‡ä»¶ï¼š{save_path}')

